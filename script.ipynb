{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__author__ = \"Christoph Hartleb\"<br>\n",
    "__copyright__ = \"Copyright 2019\"<br>\n",
    "__credits__ = [\"Christoph Hartleb\"]<br>\n",
    "__version__ = \"1.0.1\"<br>\n",
    "__email__ = \"christophhartleb@gmx.at\"<br>\n",
    "__status__ = \"Production\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Script for Webscraping. Goal of that script is to demonstrate, that variety of possibilities of how to get data with python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the script tries to get all \"H\"-entries out of an online dictionary and saves that entries into a *.csv file. The list is sorted alphabetically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sorce: __https://www.computer-dictionary-online.org__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests for getting the URL and Beautifulsoup for webscraping.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the URL here.\n",
    "r = requests.get(\"https://www.computer-dictionary-online.org/glossary/h.html\")\n",
    "# Get the content.\n",
    "c = r.content\n",
    "\n",
    "# Get the HTML element.\n",
    "soup = BeautifulSoup(c,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all list-elements in HTML.\n",
    "all = soup.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list and iterate through all a-elements.\n",
    "# Then get the text of that element and list it out\n",
    "list = []\n",
    "for item in all:\n",
    "    list.append(str(item.find_all(\"a\")[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and create namespace pd.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas dataframe object.\n",
    "df = pd.DataFrame(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a *.csv file in saves it within the scrapped data.\n",
    "df.to_csv('h_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... with Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here moves the desription forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... with lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) Parsing HTML<br>\n",
    "In this example it is tried to get some financial data from _https://finance.yahoo.com/quote/APPL?p=APPL_ and save them into a dataframe. The shows how to parse HTML data.\n",
    "\n",
    "2) Parsing XML<br>\n",
    "Exmple number two shows how to parse XML data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Parsing HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x2ab8e4d3248>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the data.\n",
    "parsed = parse(urlopen('https://finance.yahoo.com/quote/APPL?p=APPL'))\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element html at 0x2ab8d3a1c78>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the HTML element object.\n",
    "doc = parsed.getroot()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element a at 0x2ab8e727a98>,\n",
       " <Element a at 0x2ab8e7279a8>,\n",
       " <Element a at 0x2ab8e727958>,\n",
       " <Element a at 0x2ab8e727a48>,\n",
       " <Element a at 0x2ab8e727ae8>,\n",
       " <Element a at 0x2ab8e7279f8>,\n",
       " <Element a at 0x2ab8e727b38>,\n",
       " <Element a at 0x2ab8e727b88>,\n",
       " <Element a at 0x2ab8e727c28>,\n",
       " <Element a at 0x2ab8e727bd8>,\n",
       " <Element a at 0x2ab8e727e08>,\n",
       " <Element a at 0x2ab8e727c78>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the objects that display \"a\" elements.\n",
    "links = doc.findall('.//a')\n",
    "links[15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element a at 0x2ab8e727a48>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a link out of the list.\n",
    "lnk = links[18]\n",
    "lnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/portfolios'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give the URL back of the link.\n",
    "lnk.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My Portfolio'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally get the content back.\n",
    "lnk.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/watchlists',\n",
       " '/portfolios',\n",
       " '/screener',\n",
       " '/premium?ncid=navbarprem_fqbo1nu0ks0',\n",
       " '/calendar',\n",
       " '/industries',\n",
       " 'https://money.yahoo.com',\n",
       " '/videos/',\n",
       " '/news/',\n",
       " '/tech']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now a list will be created, that show all URLs conected to that site.\n",
    "urls = [lnk.get('href') for lnk in doc.findall('.//a')]\n",
    "urls[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element table at 0x2ab8e72e638>, <Element table at 0x2ab8e72e598>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now find the calls and puts data of the site.\n",
    "tables = doc.findall('.//table')\n",
    "calls = tables[1]\n",
    "puts = tables[-68:]\n",
    "calls\n",
    "puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element tr at 0x2ab8e72eb88>,\n",
       " <Element tr at 0x2ab8e72ec28>,\n",
       " <Element tr at 0x2ab8e72eea8>,\n",
       " <Element tr at 0x2ab8e72ed18>,\n",
       " <Element tr at 0x2ab8e72ee08>,\n",
       " <Element tr at 0x2ab8e72ee58>,\n",
       " <Element tr at 0x2ab8e72ef48>,\n",
       " <Element tr at 0x2ab8e72edb8>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all header lines of the elements.\n",
    "rows = calls.findall('.//tr')\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data out of the headers.\n",
    "def _unpack(row, kind='td'):\n",
    "    elts = row.findall('.//%s' % kind)\n",
    "    return [val.text_content() for val in elts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Average for Category', 'N/A']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unpack(rows[6], kind='td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unpack(rows[0], kind='th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine steps to get a dataframe. To do that first of all import libraries.\n",
    "from pandas.io.parsers import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for convertion of types automatically.\n",
    "def parse_options_data(table):\n",
    "    rows = table.findall('.//tr')\n",
    "    header = _unpack(rows[0], kind='th')\n",
    "    data = [_unpack(r) for r in rows[1:]]\n",
    "    return TextParser(data, names=header).get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Beta (5Y Monthly)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yield</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5y Average Return</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Holdings Turnover</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Last Dividend</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Average for Category</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Inception Date</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0   1\n",
       "0     Beta (5Y Monthly) NaN\n",
       "1                 Yield NaN\n",
       "2     5y Average Return NaN\n",
       "3     Holdings Turnover NaN\n",
       "4         Last Dividend NaN\n",
       "5  Average for Category NaN\n",
       "6        Inception Date NaN"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function to get the Output.\n",
    "call_data = parse_options_data(calls)\n",
    "call_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Parsing XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Response",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-843050b1e5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/nevenjovanovic/camena-neolatinlit/master/thesaurus/Becmann_historia_1.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjectify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Response"
     ]
    }
   ],
   "source": [
    "path = ''\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "skip_fields = ['PARENT_SEQ', INDICATOR_SEQ, 'DESIRED_CHANGE', 'DECIMAL_PLACES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        continue\n",
    "    el_data[child.tag] = child.pyval\n",
    "data.append(el_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "tag = '<a href = \"http://www.google.com\">Google</a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = objectify.parse(StringIO(tag)).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
